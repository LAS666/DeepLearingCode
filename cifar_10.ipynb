{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bad552cd-1099-4efd-af87-69a69b4f186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5101cc2-c557-4813-b527-0c84ac6b724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: datasets\n",
      "    Split: Train\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: datasets\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "cifar10 = torchvision.datasets.CIFAR10(\n",
    "    root='datasets',\n",
    "    train=True,\n",
    "    download=False\n",
    ")\n",
    "cifar10_test = torchvision.datasets.CIFAR10(\n",
    "    root='datasets',\n",
    "    train=False,\n",
    "    download=False\n",
    ")\n",
    "#输出数据集的信息\n",
    "print(cifar10)\n",
    "print(cifar10_test)\n",
    "\n",
    "train_filenames = []\n",
    "train_annotations = []\n",
    "test_filenames = []\n",
    "test_annotations= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff536420-548a-41e1-b405-2a83fd2019bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cifar10 官方给出的解压函数\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "anno_loc = './datasets/annotations/'\n",
    "loc_1 = './datasets/train_cifar10/'\n",
    "loc_2 = './datasets/test_cifar10/'\n",
    "\n",
    "#判断文件夹是否存在，不存在的话创建文件夹\n",
    "if os.path.exists(loc_1) == False:\n",
    "    os.mkdir(loc_1)\n",
    "if os.path.exists(loc_2) == False:\n",
    "    os.mkdir(loc_2)\n",
    "if os.path.exists(anno_loc) == False:\n",
    "    os.mkdir(anno_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0840268e-a09e-4c84-949c-e20261d9af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_img(file_dir):\n",
    "    for i in range(1,6):\n",
    "        data_name = file_dir + '/'+'data_batch_'+ str(i)\n",
    "        data_dict = unpickle(data_name)\n",
    "        print(data_name + ' is processing')\n",
    "\n",
    "        for j in range(10000):\n",
    "            img = np.reshape(data_dict[b'data'][j],(3,32,32))\n",
    "            img = np.transpose(img,(1,2,0))\n",
    "            #通道顺序为RGB\n",
    "            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            #要改成不同的形式的文件只需要将文件后缀修改即可\n",
    "            img_name = loc_1 + str((i)*10000 + j + 1) + '.png'\n",
    "            annot_img_name = str((i)*10000 + j + 1) + '.png'\n",
    "            img_annotations = data_dict[b'labels'][j]\n",
    "            train_filenames.append(annot_img_name)\n",
    "            train_annotations.append(img_annotations)\n",
    "\n",
    "            cv2.imwrite(img_name,img)\n",
    "\n",
    "        print(data_name + ' is done')\n",
    "\n",
    "\n",
    "    test_data_name = file_dir + '/test_batch'\n",
    "    print(test_data_name + ' is processing')\n",
    "    test_dict = unpickle(test_data_name)\n",
    "\n",
    "    for m in range(10000):\n",
    "        img = np.reshape(test_dict[b'data'][m], (3, 32, 32))\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        # 通道顺序为RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # 要改成不同的形式的文件只需要将文件后缀修改即可\n",
    "        img_name = loc_2 + str(m+1) + '.png'\n",
    "        annot_img_name = str(m+1) + '.png'\n",
    "        img_annotations = test_dict[b'labels'][m]\n",
    "        test_filenames.append(annot_img_name)\n",
    "        test_annotations.append(img_annotations)\n",
    "        cv2.imwrite(img_name, img)\n",
    "    print(test_data_name + ' is done')\n",
    "    print('Finish transforming to image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dddc544c-4cf7-45d1-b6c6-41d4b3b8fef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/cifar-10-batches-py/data_batch_1 is processing\n",
      "./datasets/cifar-10-batches-py/data_batch_1 is done\n",
      "./datasets/cifar-10-batches-py/data_batch_2 is processing\n",
      "./datasets/cifar-10-batches-py/data_batch_2 is done\n",
      "./datasets/cifar-10-batches-py/data_batch_3 is processing\n",
      "./datasets/cifar-10-batches-py/data_batch_3 is done\n",
      "./datasets/cifar-10-batches-py/data_batch_4 is processing\n",
      "./datasets/cifar-10-batches-py/data_batch_4 is done\n",
      "./datasets/cifar-10-batches-py/data_batch_5 is processing\n",
      "./datasets/cifar-10-batches-py/data_batch_5 is done\n",
      "./datasets/cifar-10-batches-py/test_batch is processing\n",
      "./datasets/cifar-10-batches-py/test_batch is done\n",
      "Finish transforming to image\n",
      "annotations have writen to json file\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    file_dir = './datasets/cifar-10-batches-py'\n",
    "    cifar10_img(file_dir)\n",
    "    # cifar10_annotations(file_dir)\n",
    "\n",
    "    train_annot_dict = {\n",
    "        'images': train_filenames,\n",
    "        'categories': train_annotations\n",
    "    }\n",
    "    test_annot_dict = {\n",
    "        'images':test_filenames,\n",
    "        'categories':test_annotations\n",
    "    }\n",
    "    # print(annotation)\n",
    "\n",
    "    train_json = json.dumps(train_annot_dict)\n",
    "    train_file = open('./datasets/annotations/cifar10_train.json', 'w')\n",
    "    train_file.write(train_json)\n",
    "    train_file.close()\n",
    "\n",
    "    test_json =json.dumps(test_annot_dict)\n",
    "    test_file = open('./datasets/annotations/cifar10_test.json','w')\n",
    "    test_file.write(test_json)\n",
    "    test_file.close()\n",
    "    print('annotations have writen to json file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec2aa34-53d8-4ec3-876f-db4de46b8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "#将json文件转换为csv文件\n",
    "\n",
    "def map_category_to_label(category):\n",
    "    #官方给出的类别时0-9，将它们转换为对应的类别\n",
    "    label_mapping = {\n",
    "        0: 'airplane',\n",
    "        1: 'automobile',\n",
    "        2: 'bird',\n",
    "        3: 'cat',\n",
    "        4: 'deer',\n",
    "        5: 'dog',\n",
    "        6: 'frog',\n",
    "        7: 'horse',\n",
    "        8: 'ship',\n",
    "        9: 'truck'\n",
    "    }\n",
    "    return label_mapping.get(category, category)\n",
    "\n",
    "def json_to_csv(json_file, csv_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as json_data:\n",
    "        data = json.load(json_data)\n",
    "\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as csv_data:\n",
    "        csv_writer = csv.writer(csv_data)\n",
    "\n",
    "        # 写入CSV的表头\n",
    "        csv_writer.writerow(['Image', 'Category'])\n",
    "\n",
    "        # 写入数据\n",
    "        for image, category in zip(data['images'], data['categories']):\n",
    "            # 根据映射表替换category\n",
    "            image_name = os.path.splitext(image)[0]\n",
    "            category_label = map_category_to_label(category)\n",
    "            csv_writer.writerow([image_name, category_label])\n",
    "\n",
    "\n",
    "test_json_file_path = './datasets/annotations/cifar10_test.json'\n",
    "test_csv_file_path = './datasets/annotations/testLables.csv'\n",
    "train_json_file_path = './datasets/annotations/cifar10_train.json'\n",
    "train_csv_file_path = './datasets/annotations/trainLables.csv'\n",
    "json_to_csv(test_json_file_path, test_csv_file_path)\n",
    "json_to_csv(train_json_file_path, train_csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e6845-3a4c-4db4-9bdf-badbcb49fe23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
