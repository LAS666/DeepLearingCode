{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137e9c35-49a0-4add-9878-96d746682419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a1cbed-791f-4753-907a-e5c88bafb009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system:  Windows-10-10.0.22621-SP0 10.0.22621\n",
      "Python version 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "Pandas version:  2.0.3\n",
      "Sklearn version:  1.3.2\n",
      "Pytorch version:  2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "#电脑配置信息\n",
    "print(\"Operating system: \", platform.platform(), platform.version())\n",
    "print(\"Python version\", sys.version)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Sklearn version: \", sklearn.__version__)\n",
    "print(\"Pytorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e1c549-7bb8-417c-ade7-2b6d1c9bb886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3598d5a-8d13-4900-8280-fc05c2140e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0\n",
    "TRAIN_VS_VALIDATION_SET_PERCENTANGE = 0.8\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_FULL_IMAGES_PATH = './imageclassification/temp/train'\n",
    "TEST_FULL_IMAGES_PATH = './imageclassification/temp/test'\n",
    "TRAIN_IMAGES_REORGANIZED_PATH = './imageclassification/temp/train_reorganized'\n",
    "VALID_IMAGES_REORGANIZED_PATH = './imageclassification/temp/valid_reorganized'\n",
    "TEST_IMAGES_REORGANIZED_PATH = './imageclassification/temp/test_reorganized'\n",
    "TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH = f\"{TEST_IMAGES_REORGANIZED_PATH}/unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b957145-2880-4ef6-9f81-070e0c822db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_labels = pd.read_csv('./imageclassification/temp/trainLabels.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ac7a13-49bd-444c-ac88-f5627f683922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_labels, valid_labels = train_test_split(\n",
    "    train_full_labels,\n",
    "    train_size=TRAIN_VS_VALIDATION_SET_PERCENTANGE,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5800307e-d1f5-4d88-9786-eefe9cfc8888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20331</th>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17533</th>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45820</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34808</th>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31889</th>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21244</th>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45892</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42614</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43568</th>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "id             \n",
       "20331       cat\n",
       "17533     horse\n",
       "45820       dog\n",
       "34808     horse\n",
       "31889  airplane\n",
       "...         ...\n",
       "21244  airplane\n",
       "45892       dog\n",
       "42614       dog\n",
       "43568      deer\n",
       "2733       ship\n",
       "\n",
       "[40000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47c4db4-c4c0-40d4-b180-1dccc8103102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating class path: ./imageclassification/temp/train_reorganized\\cat\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\horse\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\dog\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\airplane\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\ship\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\truck\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\bird\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\automobile\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\frog\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\deer\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\horse\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\dog\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\frog\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\deer\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\cat\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\airplane\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\bird\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\truck\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\automobile\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\ship\n"
     ]
    }
   ],
   "source": [
    "#重新组织图像文件\n",
    "def reorganize_images(labels, source_path, destination_path):\n",
    "    for label in labels[\"label\"].unique():\n",
    "        class_path = os.path.join(destination_path, str(label))\n",
    "        print(f\"Creating class path: {class_path}\")\n",
    "        os.makedirs(class_path, exist_ok=True)\n",
    "        \n",
    "    for idx, row in labels.iterrows():\n",
    "        id = row.name\n",
    "        label = row[\"label\"]\n",
    "        source_image_path = os.path.join(source_path, f\"{id}.png\")\n",
    "        destination_image_path = os.path.join(destination_path, str(label), f\"{id}.png\")\n",
    "\n",
    "        # 如果目标图像文件已经存在，则删除\n",
    "        if os.path.isfile(destination_image_path):\n",
    "            os.remove(destination_image_path)\n",
    "\n",
    "        # 复制文件到新目录\n",
    "        shutil.copy(source_image_path, destination_image_path)\n",
    "\n",
    "# 使用示例\n",
    "reorganize_images(train_labels, TRAIN_FULL_IMAGES_PATH, TRAIN_IMAGES_REORGANIZED_PATH)\n",
    "reorganize_images(valid_labels, TRAIN_FULL_IMAGES_PATH, VALID_IMAGES_REORGANIZED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e9b2cb-69ef-4ea3-819c-90adeeb35f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010])\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51224fc3-36d1-4aa4-8d55-d0a7d34a5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_images = ImageFolder(TRAIN_IMAGES_REORGANIZED_PATH, transform=transform)\n",
    "valid_images = ImageFolder(VALID_IMAGES_REORGANIZED_PATH, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9a1e45-a38c-43d1-923c-1e775a68ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 创建改进后的模型\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "680bd3cd-1198-42e1-8e6c-051366abc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5e327e-a5eb-46da-9b6b-d874a30ecab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create train and validation batch for training\n",
    "train_loader = DataLoader(dataset=train_images, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(dataset=valid_images, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83655273-82e4-41a6-b649-3549fa3f49ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 loss 0.001149882435798645\n",
      "epoch 0 batch 500 loss 0.0011153148412704468\n",
      "epoch 0 batch 1000 loss 0.0009511251449584961\n",
      "epoch 1 batch 0 loss 0.0008303983211517334\n",
      "epoch 1 batch 500 loss 0.0007655619978904724\n",
      "epoch 1 batch 1000 loss 0.0006886883378028869\n",
      "epoch 2 batch 0 loss 0.000759674847126007\n",
      "epoch 2 batch 500 loss 0.0007824352979660034\n",
      "epoch 2 batch 1000 loss 0.0006661047339439392\n",
      "epoch 3 batch 0 loss 0.000715566098690033\n",
      "epoch 3 batch 500 loss 0.0005758786797523498\n",
      "epoch 3 batch 1000 loss 0.000645692229270935\n",
      "epoch 4 batch 0 loss 0.0006279678344726562\n",
      "epoch 4 batch 500 loss 0.0005470073223114014\n",
      "epoch 4 batch 1000 loss 0.0007455144524574279\n",
      "epoch 5 batch 0 loss 0.00046290454268455505\n",
      "epoch 5 batch 500 loss 0.000778601348400116\n",
      "epoch 5 batch 1000 loss 0.000517250418663025\n",
      "epoch 6 batch 0 loss 0.0006821441054344177\n",
      "epoch 6 batch 500 loss 0.00042344552278518677\n",
      "epoch 6 batch 1000 loss 0.0004406625330448151\n",
      "epoch 7 batch 0 loss 0.0005442777276039124\n",
      "epoch 7 batch 500 loss 0.00031191065907478334\n",
      "epoch 7 batch 1000 loss 0.00040730732679367066\n",
      "epoch 8 batch 0 loss 0.0005448693633079529\n",
      "epoch 8 batch 500 loss 0.00044227972626686095\n",
      "epoch 8 batch 1000 loss 0.00029268187284469603\n",
      "epoch 9 batch 0 loss 0.000394797682762146\n",
      "epoch 9 batch 500 loss 0.00041905641555786135\n",
      "epoch 9 batch 1000 loss 0.0004808431267738342\n",
      "epoch 10 batch 0 loss 0.00032438087463378904\n",
      "epoch 10 batch 500 loss 0.0004775359034538269\n",
      "epoch 10 batch 1000 loss 0.0004484755992889404\n",
      "epoch 11 batch 0 loss 0.00028429043292999267\n",
      "epoch 11 batch 500 loss 0.00032237112522125243\n",
      "epoch 11 batch 1000 loss 0.0003611968457698822\n",
      "epoch 12 batch 0 loss 0.00029743215441703795\n",
      "epoch 12 batch 500 loss 0.00027802115678787233\n",
      "epoch 12 batch 1000 loss 0.0002682885527610779\n",
      "epoch 13 batch 0 loss 0.00031338155269622803\n",
      "epoch 13 batch 500 loss 0.0004893164932727814\n",
      "epoch 13 batch 1000 loss 0.000245374009013176\n",
      "epoch 14 batch 0 loss 0.0002601444125175476\n",
      "epoch 14 batch 500 loss 0.0002756085693836212\n",
      "epoch 14 batch 1000 loss 0.0003228957951068878\n",
      "epoch 15 batch 0 loss 0.00035760900378227234\n",
      "epoch 15 batch 500 loss 0.0003347733616828918\n",
      "epoch 15 batch 1000 loss 0.0002815631628036499\n",
      "epoch 16 batch 0 loss 0.00024819719791412353\n",
      "epoch 16 batch 500 loss 0.00023486609756946563\n",
      "epoch 16 batch 1000 loss 0.00036553019285202025\n",
      "epoch 17 batch 0 loss 0.00022628387808799744\n",
      "epoch 17 batch 500 loss 0.00020559200644493103\n",
      "epoch 17 batch 1000 loss 0.00026081684231758117\n",
      "epoch 18 batch 0 loss 0.00026279494166374205\n",
      "epoch 18 batch 500 loss 0.00022169828414916992\n",
      "epoch 18 batch 1000 loss 0.00027452099323272707\n",
      "epoch 19 batch 0 loss 0.00028686749935150145\n",
      "epoch 19 batch 500 loss 0.00019118839502334594\n",
      "epoch 19 batch 1000 loss 8.706333488225936e-05\n",
      "epoch 20 batch 0 loss 0.00015176749229431152\n",
      "epoch 20 batch 500 loss 0.00011298251152038574\n",
      "epoch 20 batch 1000 loss 0.00018685890734195708\n",
      "epoch 21 batch 0 loss 0.0001860390603542328\n",
      "epoch 21 batch 500 loss 0.0002012079507112503\n",
      "epoch 21 batch 1000 loss 0.0001361989825963974\n",
      "epoch 22 batch 0 loss 0.00013153569400310515\n",
      "epoch 22 batch 500 loss 0.0001644992083311081\n",
      "epoch 22 batch 1000 loss 0.00016642571985721588\n",
      "epoch 23 batch 0 loss 0.00015682876110076905\n",
      "epoch 23 batch 500 loss 5.312973633408547e-05\n",
      "epoch 23 batch 1000 loss 0.00014455492794513702\n",
      "epoch 24 batch 0 loss 0.00011262421309947967\n",
      "epoch 24 batch 500 loss 4.6237170696258545e-05\n",
      "epoch 24 batch 1000 loss 5.2642188966274264e-05\n",
      "epoch 25 batch 0 loss 0.00014371129870414733\n",
      "epoch 25 batch 500 loss 0.00010445891320705413\n",
      "epoch 25 batch 1000 loss 0.0002592242360115051\n",
      "epoch 26 batch 0 loss 0.00010847143083810807\n",
      "epoch 26 batch 500 loss 5.9628598392009736e-05\n",
      "epoch 26 batch 1000 loss 4.4374119490385054e-05\n",
      "epoch 27 batch 0 loss 0.00010758350789546966\n",
      "epoch 27 batch 500 loss 0.00011955498903989791\n",
      "epoch 27 batch 1000 loss 7.034125924110413e-05\n",
      "epoch 28 batch 0 loss 8.731304854154587e-05\n",
      "epoch 28 batch 500 loss 8.5860975086689e-05\n",
      "epoch 28 batch 1000 loss 9.096883982419967e-05\n",
      "epoch 29 batch 0 loss 0.00015860502421855926\n",
      "epoch 29 batch 500 loss 0.00010513366758823395\n",
      "epoch 29 batch 1000 loss 0.00016990964114665984\n",
      "epoch 30 batch 0 loss 0.00010981599986553193\n",
      "epoch 30 batch 500 loss 0.0001053176000714302\n",
      "epoch 30 batch 1000 loss 1.9959630444645883e-05\n",
      "epoch 31 batch 0 loss 8.114983886480331e-05\n",
      "epoch 31 batch 500 loss 4.772406071424484e-05\n",
      "epoch 31 batch 1000 loss 9.7829669713974e-05\n",
      "epoch 32 batch 0 loss 5.229978263378143e-05\n",
      "epoch 32 batch 500 loss 6.66506588459015e-05\n",
      "epoch 32 batch 1000 loss 0.00015052174031734468\n",
      "epoch 33 batch 0 loss 6.227418780326843e-05\n",
      "epoch 33 batch 500 loss 0.00023766957223415376\n",
      "epoch 33 batch 1000 loss 0.00019098232686519623\n",
      "epoch 34 batch 0 loss 1.7277799546718598e-05\n",
      "epoch 34 batch 500 loss 3.9933901280164716e-05\n",
      "epoch 34 batch 1000 loss 1.38573432341218e-05\n",
      "epoch 35 batch 0 loss 3.747506067156792e-05\n",
      "epoch 35 batch 500 loss 2.953178994357586e-05\n",
      "epoch 35 batch 1000 loss 0.00013731949031352996\n",
      "epoch 36 batch 0 loss 1.591622270643711e-05\n",
      "epoch 36 batch 500 loss 1.4324106276035309e-05\n",
      "epoch 36 batch 1000 loss 8.577346056699752e-05\n",
      "epoch 37 batch 0 loss 2.5540411472320557e-05\n",
      "epoch 37 batch 500 loss 9.055253863334655e-05\n",
      "epoch 37 batch 1000 loss 6.514301151037216e-05\n",
      "epoch 38 batch 0 loss 3.779527544975281e-05\n",
      "epoch 38 batch 500 loss 6.548862159252167e-05\n",
      "epoch 38 batch 1000 loss 0.00010848099738359452\n",
      "epoch 39 batch 0 loss 4.404934868216514e-05\n",
      "epoch 39 batch 500 loss 1.6197746619582177e-05\n",
      "epoch 39 batch 1000 loss 1.7029499635100365e-05\n",
      "epoch 40 batch 0 loss 8.698871731758118e-05\n",
      "epoch 40 batch 500 loss 7.923957891762256e-06\n",
      "epoch 40 batch 1000 loss 3.800342231988907e-05\n",
      "epoch 41 batch 0 loss 5.502369254827499e-06\n",
      "epoch 41 batch 500 loss 1.4701480977237224e-05\n",
      "epoch 41 batch 1000 loss 5.467453971505165e-05\n",
      "epoch 42 batch 0 loss 2.7643514797091484e-05\n",
      "epoch 42 batch 500 loss 6.275597214698791e-05\n",
      "epoch 42 batch 1000 loss 7.163547724485397e-05\n",
      "epoch 43 batch 0 loss 8.73192921280861e-05\n",
      "epoch 43 batch 500 loss 3.56566421687603e-05\n",
      "epoch 43 batch 1000 loss 9.40963625907898e-06\n",
      "epoch 44 batch 0 loss 1.6801806166768074e-05\n",
      "epoch 44 batch 500 loss 2.9154427349567415e-05\n",
      "epoch 44 batch 1000 loss 4.0031835436820984e-05\n",
      "epoch 45 batch 0 loss 2.819281257688999e-05\n",
      "epoch 45 batch 500 loss 3.42990905046463e-05\n",
      "epoch 45 batch 1000 loss 4.153237491846085e-05\n",
      "epoch 46 batch 0 loss 2.20867320895195e-05\n",
      "epoch 46 batch 500 loss 6.765187252312899e-06\n",
      "epoch 46 batch 1000 loss 2.1449897438287733e-05\n",
      "epoch 47 batch 0 loss 4.910302814096212e-06\n",
      "epoch 47 batch 500 loss 6.389782764017582e-06\n",
      "epoch 47 batch 1000 loss 1.0656443424522877e-05\n",
      "epoch 48 batch 0 loss 2.482367306947708e-05\n",
      "epoch 48 batch 500 loss 8.515305817127227e-05\n",
      "epoch 48 batch 1000 loss 1.0402711108326911e-05\n",
      "epoch 49 batch 0 loss 1.0471309535205364e-05\n",
      "epoch 49 batch 500 loss 4.623034968972206e-05\n",
      "epoch 49 batch 1000 loss 3.073368035256863e-05\n",
      "epoch 50 batch 0 loss 2.139065973460674e-05\n",
      "epoch 50 batch 500 loss 4.641708731651306e-05\n",
      "epoch 50 batch 1000 loss 3.301722463220358e-06\n",
      "epoch 51 batch 0 loss 4.458419606089592e-05\n",
      "epoch 51 batch 500 loss 0.00012140574306249618\n",
      "epoch 51 batch 1000 loss 4.9486037343740466e-05\n",
      "epoch 52 batch 0 loss 1.0450804606080056e-05\n",
      "epoch 52 batch 500 loss 4.231571685522795e-06\n",
      "epoch 52 batch 1000 loss 1.7443157732486725e-05\n",
      "epoch 53 batch 0 loss 9.154640138149261e-05\n",
      "epoch 53 batch 500 loss 7.75236114859581e-05\n",
      "epoch 53 batch 1000 loss 2.8023816645145417e-05\n",
      "epoch 54 batch 0 loss 6.440550554543734e-06\n",
      "epoch 54 batch 500 loss 8.28951969742775e-06\n",
      "epoch 54 batch 1000 loss 4.1719451546669e-06\n",
      "epoch 55 batch 0 loss 6.730206310749054e-06\n",
      "epoch 55 batch 500 loss 2.226816862821579e-05\n",
      "epoch 55 batch 1000 loss 1.3617129996418952e-05\n",
      "epoch 56 batch 0 loss 1.8420780077576638e-05\n",
      "epoch 56 batch 500 loss 9.175392985343934e-05\n",
      "epoch 56 batch 1000 loss 4.038707353174687e-06\n",
      "epoch 57 batch 0 loss 1.4344651252031326e-05\n",
      "epoch 57 batch 500 loss 3.9899401366710665e-05\n",
      "epoch 57 batch 1000 loss 1.417529210448265e-05\n",
      "epoch 58 batch 0 loss 9.602936916053296e-06\n",
      "epoch 58 batch 500 loss 3.495627548545599e-06\n",
      "epoch 58 batch 1000 loss 3.719658777117729e-05\n",
      "epoch 59 batch 0 loss 9.181784465909004e-06\n",
      "epoch 59 batch 500 loss 3.0029071494936945e-06\n",
      "epoch 59 batch 1000 loss 2.3600659333169462e-06\n",
      "epoch 60 batch 0 loss 6.754656322300434e-06\n",
      "epoch 60 batch 500 loss 1.6258999705314637e-05\n",
      "epoch 60 batch 1000 loss 2.7376567013561727e-06\n",
      "epoch 61 batch 0 loss 1.6239484772086143e-05\n",
      "epoch 61 batch 500 loss 2.478514052927494e-05\n",
      "epoch 61 batch 1000 loss 1.8055668333545326e-06\n",
      "epoch 62 batch 0 loss 7.645963225513696e-06\n",
      "epoch 62 batch 500 loss 4.196693189442158e-06\n",
      "epoch 62 batch 1000 loss 3.878745250403881e-06\n",
      "epoch 63 batch 0 loss 0.00010646451264619827\n",
      "epoch 63 batch 500 loss 4.455886036157608e-05\n",
      "epoch 63 batch 1000 loss 4.339435324072838e-05\n",
      "epoch 64 batch 0 loss 5.287755280733109e-06\n",
      "epoch 64 batch 500 loss 1.6907155513763426e-05\n",
      "epoch 64 batch 1000 loss 2.480652928352356e-05\n",
      "epoch 65 batch 0 loss 7.387495040893554e-05\n",
      "epoch 65 batch 500 loss 6.74584461376071e-06\n",
      "epoch 65 batch 1000 loss 8.181393146514892e-06\n",
      "epoch 66 batch 0 loss 1.0864597279578448e-06\n",
      "epoch 66 batch 500 loss 3.3115096390247344e-05\n",
      "epoch 66 batch 1000 loss 8.01193118095398e-05\n",
      "epoch 67 batch 0 loss 8.298411034047604e-06\n",
      "epoch 67 batch 500 loss 4.559450969099999e-05\n",
      "epoch 67 batch 1000 loss 1.5374102629721164e-05\n",
      "epoch 68 batch 0 loss 5.159283988177776e-06\n",
      "epoch 68 batch 500 loss 3.833232680335641e-06\n",
      "epoch 68 batch 1000 loss 1.4665599446743727e-06\n",
      "epoch 69 batch 0 loss 6.790108163841068e-07\n",
      "epoch 69 batch 500 loss 3.5610068589448926e-05\n",
      "epoch 69 batch 1000 loss 7.279020268470049e-06\n",
      "epoch 70 batch 0 loss 3.984585404396057e-06\n",
      "epoch 70 batch 500 loss 2.8909390792250635e-05\n",
      "epoch 70 batch 1000 loss 1.6869718208909036e-05\n",
      "epoch 71 batch 0 loss 2.943507628515363e-06\n",
      "epoch 71 batch 500 loss 3.5129846073687078e-06\n",
      "epoch 71 batch 1000 loss 1.4775783056393265e-06\n",
      "epoch 72 batch 0 loss 4.051133990287781e-06\n",
      "epoch 72 batch 500 loss 5.982153816148639e-07\n",
      "epoch 72 batch 1000 loss 1.4878242276608944e-05\n",
      "epoch 73 batch 0 loss 1.1599261779338122e-06\n",
      "epoch 73 batch 500 loss 6.473124958574772e-06\n",
      "epoch 73 batch 1000 loss 5.056682974100113e-05\n",
      "epoch 74 batch 0 loss 5.5104300379753114e-05\n",
      "epoch 74 batch 500 loss 2.017888706177473e-06\n",
      "epoch 74 batch 1000 loss 1.72146912664175e-05\n",
      "epoch 75 batch 0 loss 7.80574744567275e-06\n",
      "epoch 75 batch 500 loss 4.70036156475544e-05\n",
      "epoch 75 batch 1000 loss 4.214275162667036e-06\n",
      "epoch 76 batch 0 loss 1.3789822347462178e-05\n",
      "epoch 76 batch 500 loss 4.6812523156404494e-05\n",
      "epoch 76 batch 1000 loss 1.1188266798853874e-05\n",
      "epoch 77 batch 0 loss 2.8047239407896994e-05\n",
      "epoch 77 batch 500 loss 1.7813919112086297e-06\n",
      "epoch 77 batch 1000 loss 3.82141605950892e-06\n",
      "epoch 78 batch 0 loss 3.2721650786697866e-06\n",
      "epoch 78 batch 500 loss 7.38834380172193e-07\n",
      "epoch 78 batch 1000 loss 2.328374609351158e-05\n",
      "epoch 79 batch 0 loss 1.0029181838035584e-05\n",
      "epoch 79 batch 500 loss 6.986278109252453e-06\n",
      "epoch 79 batch 1000 loss 2.142464742064476e-06\n",
      "epoch 80 batch 0 loss 1.75578985363245e-07\n",
      "epoch 80 batch 500 loss 7.657051319256425e-07\n",
      "epoch 80 batch 1000 loss 2.5216922163963318e-05\n",
      "epoch 81 batch 0 loss 5.355279427021742e-06\n",
      "epoch 81 batch 500 loss 4.1137292282655833e-07\n",
      "epoch 81 batch 1000 loss 3.9571791887283324e-05\n",
      "epoch 82 batch 0 loss 1.5671513392589986e-07\n",
      "epoch 82 batch 500 loss 0.00011681319028139114\n",
      "epoch 82 batch 1000 loss 1.3081680051982403e-05\n",
      "epoch 83 batch 0 loss 3.075495362281799e-05\n",
      "epoch 83 batch 500 loss 7.210686802864075e-05\n",
      "epoch 83 batch 1000 loss 3.856199234724045e-05\n",
      "epoch 84 batch 0 loss 1.9285297021269798e-06\n",
      "epoch 84 batch 500 loss 1.924043521285057e-05\n",
      "epoch 84 batch 1000 loss 4.676829278469086e-05\n",
      "epoch 85 batch 0 loss 2.415673341602087e-06\n",
      "epoch 85 batch 500 loss 4.26325760781765e-06\n",
      "epoch 85 batch 1000 loss 2.0820939913392066e-05\n",
      "epoch 86 batch 0 loss 1.2335751205682755e-05\n",
      "epoch 86 batch 500 loss 9.876861423254013e-05\n",
      "epoch 86 batch 1000 loss 2.0571411587297915e-06\n",
      "epoch 87 batch 0 loss 1.7905263230204583e-06\n",
      "epoch 87 batch 500 loss 7.059627771377564e-05\n",
      "epoch 87 batch 1000 loss 2.7410855516791344e-05\n",
      "epoch 88 batch 0 loss 4.4733989983797075e-05\n",
      "epoch 88 batch 500 loss 2.303377538919449e-05\n",
      "epoch 88 batch 1000 loss 4.224958829581738e-06\n",
      "epoch 89 batch 0 loss 3.2771084806881843e-07\n",
      "epoch 89 batch 500 loss 3.686495590955019e-06\n",
      "epoch 89 batch 1000 loss 2.400892227888107e-05\n",
      "epoch 90 batch 0 loss 5.570970941334963e-06\n",
      "epoch 90 batch 500 loss 3.844460099935532e-05\n",
      "epoch 90 batch 1000 loss 1.0165141895413398e-05\n",
      "epoch 91 batch 0 loss 2.0982490852475165e-05\n",
      "epoch 91 batch 500 loss 4.431537352502346e-06\n",
      "epoch 91 batch 1000 loss 3.642788156867027e-05\n",
      "epoch 92 batch 0 loss 1.2492513051256536e-06\n",
      "epoch 92 batch 500 loss 5.704414565116167e-06\n",
      "epoch 92 batch 1000 loss 1.2391199124976993e-06\n",
      "epoch 93 batch 0 loss 1.452353410422802e-05\n",
      "epoch 93 batch 500 loss 1.5893997624516486e-05\n",
      "epoch 93 batch 1000 loss 2.615265781059861e-06\n",
      "epoch 94 batch 0 loss 1.1312959715723992e-05\n",
      "epoch 94 batch 500 loss 3.5584683064371346e-06\n",
      "epoch 94 batch 1000 loss 1.575709693133831e-05\n",
      "epoch 95 batch 0 loss 5.996539839543403e-07\n",
      "epoch 95 batch 500 loss 4.7160543501377105e-05\n",
      "epoch 95 batch 1000 loss 4.415834555402398e-07\n",
      "epoch 96 batch 0 loss 1.6268257750198244e-06\n",
      "epoch 96 batch 500 loss 2.88182757794857e-05\n",
      "epoch 96 batch 1000 loss 6.5845730714499954e-06\n",
      "epoch 97 batch 0 loss 1.752420701086521e-05\n",
      "epoch 97 batch 500 loss 8.282736875116826e-06\n",
      "epoch 97 batch 1000 loss 2.4928562343120575e-05\n",
      "epoch 98 batch 0 loss 6.915401900187135e-07\n",
      "epoch 98 batch 500 loss 7.724343240261078e-05\n",
      "epoch 98 batch 1000 loss 9.850517846643925e-06\n",
      "epoch 99 batch 0 loss 1.6077397391200064e-05\n",
      "epoch 99 batch 500 loss 1.3046514242887497e-05\n",
      "epoch 99 batch 1000 loss 3.101737797260285e-05\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        #获取输入\n",
    "        sample_images, sample_labels = batch\n",
    "\n",
    "        # 参数梯度归零\n",
    "        # 默认情况下，pytorch在反向传递中会累积梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        predicted_labels = net(sample_images)\n",
    "        loss = criterion(predicted_labels, sample_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # 每五百个小批量打印一次\n",
    "        if batch_index % 500 == 0:\n",
    "            print(f\"epoch {epoch} batch {batch_index} loss {running_loss / 2000}\")\n",
    "        running_loss = 0\n",
    "\n",
    "    loss = criterion(predicted_labels, sample_labels)\n",
    "    train_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c08a3f0-2cbc-401a-b9b9-f624a0042f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set linked successfully\n"
     ]
    }
   ],
   "source": [
    "# 创建测试集图像目录\n",
    "os.makedirs(TEST_IMAGES_REORGANIZED_PATH, exist_ok=True)\n",
    "\n",
    "# 检查是否已经存在链接\n",
    "if os.path.islink(TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH):\n",
    "    print(\"Test set has been already linked\")\n",
    "else:\n",
    "    # 创建符号链接\n",
    "    os.system(f\"mklink /D {TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH} {TEST_FULL_IMAGES_PATH}\")\n",
    "    print(\"Test set linked successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ca0134-95c6-43f7-9128-04586865b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = ImageFolder(TEST_IMAGES_REORGANIZED_PATH, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cea7889-94f9-4aa9-b402-9b6d22587338",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_images, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "preds = []\n",
    "for X, _ in test_loader:\n",
    "    y_hat = net(X)\n",
    "    preds.extend(y_hat.argmax(dim=1))\n",
    "# 从测试集图像路径中提取图像的 id（去掉路径前缀和文件扩展名）\n",
    "# 从测试集图像路径中提取图像的 id（去掉路径前缀和文件扩展名）\n",
    "ids = [os.path.splitext(os.path.basename(path))[0] for path, _ in test_loader.dataset.imgs]\n",
    "\n",
    "# 创建一个DataFrame，其中包含图像的id和对应的预测标签\n",
    "df = pd.DataFrame({'id': ids, 'label': map(lambda i: train_images.classes[i], preds)})\n",
    "\n",
    "# 将DataFrame保存到CSV文件中\n",
    "df.to_csv('./imageclassification/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9dbbde5-609e-48cc-a6a4-bb533fc6c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 7509\n",
      "0.7509\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取正确标签的CSV文件，假设文件名为 'true_labels.csv'\n",
    "true_labels = pd.read_csv('./imageclassification/temp/testLables.csv', index_col='id')\n",
    "\n",
    "# 读取预测标签的CSV文件，假设文件名为 'predicted_labels.csv'\n",
    "predicted_labels = pd.read_csv('./imageclassification/working/submission.csv', index_col='id')\n",
    "\n",
    "# 将两个DataFrame按照id进行合并\n",
    "merged_data = pd.merge(true_labels, predicted_labels, left_index=True, right_index=True, suffixes=('_true', '_predicted'))\n",
    "\n",
    "# 统计正确的数量\n",
    "correct_count = (merged_data['label_true'] == merged_data['label_predicted']).sum()\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "accury = correct_count/10000\n",
    "print(accury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25467c2-239f-42ce-a189-82ea29f3b12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
