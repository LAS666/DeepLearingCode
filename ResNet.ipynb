{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ddd098-875e-4bb1-86e0-875c9232505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d863a0c-6e80-4a22-8c7d-4bb043ba1d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system:  Windows-10-10.0.22621-SP0 10.0.22621\n",
      "Python version 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "Pandas version:  2.0.3\n",
      "Sklearn version:  1.3.2\n",
      "Pytorch version:  2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "#电脑配置信息\n",
    "print(\"Operating system: \", platform.platform(), platform.version())\n",
    "print(\"Python version\", sys.version)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Sklearn version: \", sklearn.__version__)\n",
    "print(\"Pytorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e242d2-7718-4e48-ad6c-345c5580af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f2981a-80e6-4981-9f1d-e493ad8ebb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0\n",
    "TRAIN_VS_VALIDATION_SET_PERCENTANGE = 0.8\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_FULL_IMAGES_PATH = './imageclassification/temp/train'\n",
    "TEST_FULL_IMAGES_PATH = './imageclassification/temp/test'\n",
    "TRAIN_IMAGES_REORGANIZED_PATH = './imageclassification/temp/train_reorganized'\n",
    "VALID_IMAGES_REORGANIZED_PATH = './imageclassification/temp/valid_reorganized'\n",
    "TEST_IMAGES_REORGANIZED_PATH = './imageclassification/temp/test_reorganized'\n",
    "TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH = f\"{TEST_IMAGES_REORGANIZED_PATH}/unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516c7a55-b8a3-493e-a618-534940a1b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_labels = pd.read_csv('./imageclassification/temp/trainLabels.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fba2a4f-4438-4c90-a779-35ae4d9073b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_labels, valid_labels = train_test_split(\n",
    "    train_full_labels,\n",
    "    train_size=TRAIN_VS_VALIDATION_SET_PERCENTANGE,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12dc4266-91a3-46d4-953e-79dbc1e876d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20331</th>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17533</th>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45820</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34808</th>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31889</th>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21244</th>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45892</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42614</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43568</th>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "id             \n",
       "20331       cat\n",
       "17533     horse\n",
       "45820       dog\n",
       "34808     horse\n",
       "31889  airplane\n",
       "...         ...\n",
       "21244  airplane\n",
       "45892       dog\n",
       "42614       dog\n",
       "43568      deer\n",
       "2733       ship\n",
       "\n",
       "[40000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3204adf-00f0-48dd-904e-16d4e9cee290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating class path: ./imageclassification/temp/train_reorganized\\cat\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\horse\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\dog\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\airplane\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\ship\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\truck\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\bird\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\automobile\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\frog\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\deer\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\horse\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\dog\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\frog\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\deer\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\cat\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\airplane\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\bird\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\truck\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\automobile\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\ship\n"
     ]
    }
   ],
   "source": [
    "#重新组织图像文件\n",
    "def reorganize_images(labels, source_path, destination_path):\n",
    "    for label in labels[\"label\"].unique():\n",
    "        class_path = os.path.join(destination_path, str(label))\n",
    "        print(f\"Creating class path: {class_path}\")\n",
    "        os.makedirs(class_path, exist_ok=True)\n",
    "        \n",
    "    for idx, row in labels.iterrows():\n",
    "        id = row.name\n",
    "        label = row[\"label\"]\n",
    "        source_image_path = os.path.join(source_path, f\"{id}.png\")\n",
    "        destination_image_path = os.path.join(destination_path, str(label), f\"{id}.png\")\n",
    "\n",
    "        # 如果目标图像文件已经存在，则删除\n",
    "        if os.path.isfile(destination_image_path):\n",
    "            os.remove(destination_image_path)\n",
    "\n",
    "        # 复制文件到新目录\n",
    "        shutil.copy(source_image_path, destination_image_path)\n",
    "\n",
    "# 使用示例\n",
    "reorganize_images(train_labels, TRAIN_FULL_IMAGES_PATH, TRAIN_IMAGES_REORGANIZED_PATH)\n",
    "reorganize_images(valid_labels, TRAIN_FULL_IMAGES_PATH, VALID_IMAGES_REORGANIZED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19435d2-c342-40f2-9884-d84fc2052543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010])\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9d309c-a17f-434e-ab5a-0b1dc1954f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_images = ImageFolder(TRAIN_IMAGES_REORGANIZED_PATH, transform=transform)\n",
    "valid_images = ImageFolder(VALID_IMAGES_REORGANIZED_PATH, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c624451-9df6-48c6-911f-349c762485de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.downsample(identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ResNet(BasicBlock, [2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5d6050-74b3-4af9-abc9-531f122a6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28a38c36-6ce9-461b-8e28-485880d77545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create train and validation batch for training\n",
    "train_loader = DataLoader(dataset=train_images, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(dataset=valid_images, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "407fe6d9-696b-49b3-95d1-df1c5eaf56ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 loss 0.0012187812328338624\n",
      "epoch 0 batch 500 loss 0.0006368532776832581\n",
      "epoch 0 batch 1000 loss 0.0005444280505180358\n",
      "epoch 1 batch 0 loss 0.0006210973262786865\n",
      "epoch 1 batch 500 loss 0.0003575623035430908\n",
      "epoch 1 batch 1000 loss 0.000649368405342102\n",
      "epoch 2 batch 0 loss 0.0004910331964492798\n",
      "epoch 2 batch 500 loss 0.0005058587789535522\n",
      "epoch 2 batch 1000 loss 0.0004096373617649078\n",
      "epoch 3 batch 0 loss 0.00044260162115097043\n",
      "epoch 3 batch 500 loss 0.0004413345158100128\n",
      "epoch 3 batch 1000 loss 0.00038347592949867246\n",
      "epoch 4 batch 0 loss 0.00023006980121135712\n",
      "epoch 4 batch 500 loss 0.00023925028741359711\n",
      "epoch 4 batch 1000 loss 0.00042264413833618166\n",
      "epoch 5 batch 0 loss 0.00028389677405357363\n",
      "epoch 5 batch 500 loss 0.00032715144753456114\n",
      "epoch 5 batch 1000 loss 0.0002906356155872345\n",
      "epoch 6 batch 0 loss 0.00022626714408397676\n",
      "epoch 6 batch 500 loss 0.00021137554943561555\n",
      "epoch 6 batch 1000 loss 0.0002653398215770721\n",
      "epoch 7 batch 0 loss 8.055152744054794e-05\n",
      "epoch 7 batch 500 loss 0.00019231653213500977\n",
      "epoch 7 batch 1000 loss 0.00016636258363723756\n",
      "epoch 8 batch 0 loss 0.00011536724120378494\n",
      "epoch 8 batch 500 loss 0.00010399330407381058\n",
      "epoch 8 batch 1000 loss 0.00010407281666994094\n",
      "epoch 9 batch 0 loss 4.740286618471146e-05\n",
      "epoch 9 batch 500 loss 0.00010615048557519913\n",
      "epoch 9 batch 1000 loss 0.00018488942086696623\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        #获取输入\n",
    "        sample_images, sample_labels = batch\n",
    "\n",
    "        # 参数梯度归零\n",
    "        # 默认情况下，pytorch在反向传递中会累积梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        predicted_labels = net(sample_images)\n",
    "        loss = criterion(predicted_labels, sample_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # 每五百个小批量打印一次\n",
    "        if batch_index % 500 == 0:\n",
    "            print(f\"epoch {epoch} batch {batch_index} loss {running_loss / 2000}\")\n",
    "        running_loss = 0\n",
    "\n",
    "    loss = criterion(predicted_labels, sample_labels)\n",
    "    train_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d0399e2-fdff-4c9d-bc52-3e673f7323d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set linked successfully\n"
     ]
    }
   ],
   "source": [
    "# 创建测试集图像目录\n",
    "os.makedirs(TEST_IMAGES_REORGANIZED_PATH, exist_ok=True)\n",
    "\n",
    "# 检查是否已经存在链接\n",
    "if os.path.islink(TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH):\n",
    "    print(\"Test set has been already linked\")\n",
    "else:\n",
    "    # 创建符号链接\n",
    "    os.system(f\"mklink /D {TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH} {TEST_FULL_IMAGES_PATH}\")\n",
    "    print(\"Test set linked successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "123451df-b0ae-4a45-bf25-15c34d8dda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = ImageFolder(TEST_IMAGES_REORGANIZED_PATH, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9895e5c4-66d7-4f9b-8c41-ca662dc92e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_images, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "preds = []\n",
    "for X, _ in test_loader:\n",
    "    y_hat = net(X)\n",
    "    preds.extend(y_hat.argmax(dim=1))\n",
    "# 从测试集图像路径中提取图像的 id（去掉路径前缀和文件扩展名）\n",
    "# 从测试集图像路径中提取图像的 id（去掉路径前缀和文件扩展名）\n",
    "ids = [os.path.splitext(os.path.basename(path))[0] for path, _ in test_loader.dataset.imgs]\n",
    "\n",
    "# 创建一个DataFrame，其中包含图像的id和对应的预测标签\n",
    "df = pd.DataFrame({'id': ids, 'label': map(lambda i: train_images.classes[i], preds)})\n",
    "\n",
    "# 将DataFrame保存到CSV文件中\n",
    "df.to_csv('./imageclassification/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82a579ec-4ce4-4f5b-9dd9-6f270c109290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 7088\n",
      "0.7088\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取正确标签的CSV文件，假设文件名为 'true_labels.csv'\n",
    "true_labels = pd.read_csv('./imageclassification/temp/testLables.csv', index_col='id')\n",
    "\n",
    "# 读取预测标签的CSV文件，假设文件名为 'predicted_labels.csv'\n",
    "predicted_labels = pd.read_csv('./imageclassification/working/submission.csv', index_col='id')\n",
    "\n",
    "# 将两个DataFrame按照id进行合并\n",
    "merged_data = pd.merge(true_labels, predicted_labels, left_index=True, right_index=True, suffixes=('_true', '_predicted'))\n",
    "\n",
    "# 统计正确的数量\n",
    "correct_count = (merged_data['label_true'] == merged_data['label_predicted']).sum()\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "accury = correct_count/10000\n",
    "print(accury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beff1f9-1783-49d2-999c-633820dbc58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
