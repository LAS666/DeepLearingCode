{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ddd098-875e-4bb1-86e0-875c9232505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d863a0c-6e80-4a22-8c7d-4bb043ba1d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system:  Windows-10-10.0.22621-SP0 10.0.22621\n",
      "Python version 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n",
      "Pandas version:  2.0.3\n",
      "Sklearn version:  1.3.2\n",
      "Pytorch version:  2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "#电脑配置信息\n",
    "print(\"Operating system: \", platform.platform(), platform.version())\n",
    "print(\"Python version\", sys.version)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Sklearn version: \", sklearn.__version__)\n",
    "print(\"Pytorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e242d2-7718-4e48-ad6c-345c5580af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f2981a-80e6-4981-9f1d-e493ad8ebb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0\n",
    "TRAIN_VS_VALIDATION_SET_PERCENTANGE = 0.8\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_FULL_IMAGES_PATH = './imageclassification/temp/train'\n",
    "TEST_FULL_IMAGES_PATH = './imageclassification/temp/test'\n",
    "TRAIN_IMAGES_REORGANIZED_PATH = './imageclassification/temp/train_reorganized'\n",
    "VALID_IMAGES_REORGANIZED_PATH = './imageclassification/temp/valid_reorganized'\n",
    "TEST_IMAGES_REORGANIZED_PATH = './imageclassification/temp/test_reorganized'\n",
    "TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH = f\"{TEST_IMAGES_REORGANIZED_PATH}/unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516c7a55-b8a3-493e-a618-534940a1b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_labels = pd.read_csv('./imageclassification/temp/trainLabels.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fba2a4f-4438-4c90-a779-35ae4d9073b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_labels, valid_labels = train_test_split(\n",
    "    train_full_labels,\n",
    "    train_size=TRAIN_VS_VALIDATION_SET_PERCENTANGE,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12dc4266-91a3-46d4-953e-79dbc1e876d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20331</th>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17533</th>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45820</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34808</th>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31889</th>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21244</th>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45892</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42614</th>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43568</th>\n",
       "      <td>deer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>ship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "id             \n",
       "20331       cat\n",
       "17533     horse\n",
       "45820       dog\n",
       "34808     horse\n",
       "31889  airplane\n",
       "...         ...\n",
       "21244  airplane\n",
       "45892       dog\n",
       "42614       dog\n",
       "43568      deer\n",
       "2733       ship\n",
       "\n",
       "[40000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3204adf-00f0-48dd-904e-16d4e9cee290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating class path: ./imageclassification/temp/train_reorganized\\cat\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\horse\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\dog\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\airplane\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\ship\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\truck\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\bird\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\automobile\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\frog\n",
      "Creating class path: ./imageclassification/temp/train_reorganized\\deer\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\horse\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\dog\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\frog\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\deer\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\cat\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\airplane\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\bird\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\truck\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\automobile\n",
      "Creating class path: ./imageclassification/temp/valid_reorganized\\ship\n"
     ]
    }
   ],
   "source": [
    "#重新组织图像文件\n",
    "def reorganize_images(labels, source_path, destination_path):\n",
    "    for label in labels[\"label\"].unique():\n",
    "        class_path = os.path.join(destination_path, str(label))\n",
    "        print(f\"Creating class path: {class_path}\")\n",
    "        os.makedirs(class_path, exist_ok=True)\n",
    "        \n",
    "    for idx, row in labels.iterrows():\n",
    "        id = row.name\n",
    "        label = row[\"label\"]\n",
    "        source_image_path = os.path.join(source_path, f\"{id}.png\")\n",
    "        destination_image_path = os.path.join(destination_path, str(label), f\"{id}.png\")\n",
    "\n",
    "        # 如果目标图像文件已经存在，则删除\n",
    "        if os.path.isfile(destination_image_path):\n",
    "            os.remove(destination_image_path)\n",
    "\n",
    "        # 复制文件到新目录\n",
    "        shutil.copy(source_image_path, destination_image_path)\n",
    "\n",
    "# 使用示例\n",
    "reorganize_images(train_labels, TRAIN_FULL_IMAGES_PATH, TRAIN_IMAGES_REORGANIZED_PATH)\n",
    "reorganize_images(valid_labels, TRAIN_FULL_IMAGES_PATH, VALID_IMAGES_REORGANIZED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19435d2-c342-40f2-9884-d84fc2052543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
    "std = torch.tensor([0.2023, 0.1994, 0.2010])\n",
    "\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9d309c-a17f-434e-ab5a-0b1dc1954f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_images = ImageFolder(TRAIN_IMAGES_REORGANIZED_PATH, transform=transform)\n",
    "valid_images = ImageFolder(VALID_IMAGES_REORGANIZED_PATH, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "858f1c3b-da57-4581-8879-46a7ef292b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n",
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#图片展示\n",
    "def display_img(img):\n",
    "\n",
    "    PIL_RGB_image = img.permute(1, 2, 0)\n",
    "    img = PIL_RGB_image * std + mean\n",
    "    plt.imshow(img.numpy())\n",
    "\n",
    "sample_image, sample_label_index = train_images[0]\n",
    "display_img(sample_image)\n",
    "print(train_images.classes[sample_label_index])\n",
    "print(sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c624451-9df6-48c6-911f-349c762485de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立一个简单的模型\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义一个基本的残差块\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 如果输入通道数与输出通道数不一致，添加一个额外的卷积层进行调整\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.downsample(residual)  # 将残差块的输出与输入相加\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 定义ResNet模型\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.residual_block1 = ResidualBlock(6, 16)\n",
    "        self.residual_block2 = ResidualBlock(16, 16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.residual_block1(x)\n",
    "        x = self.residual_block2(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# 创建ResNet模型\n",
    "net = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e5d6050-74b3-4af9-abc9-531f122a6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28a38c36-6ce9-461b-8e28-485880d77545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create train and validation batch for training\n",
    "train_loader = DataLoader(dataset=train_images, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(dataset=valid_images, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407fe6d9-696b-49b3-95d1-df1c5eaf56ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 loss 0.0011581249237060547\n",
      "epoch 0 batch 500 loss 0.001119904398918152\n",
      "epoch 0 batch 1000 loss 0.0010043940544128419\n",
      "epoch 1 batch 0 loss 0.0010419604778289795\n",
      "epoch 1 batch 500 loss 0.0010200440883636475\n",
      "epoch 1 batch 1000 loss 0.0007678745985031128\n",
      "epoch 2 batch 0 loss 0.0008808378577232361\n",
      "epoch 2 batch 500 loss 0.0007972477674484253\n",
      "epoch 2 batch 1000 loss 0.0007993199229240417\n",
      "epoch 3 batch 0 loss 0.000632637619972229\n",
      "epoch 3 batch 500 loss 0.0007476910948753356\n",
      "epoch 3 batch 1000 loss 0.0006561285853385926\n",
      "epoch 4 batch 0 loss 0.0006897044777870178\n",
      "epoch 4 batch 500 loss 0.0006347579956054687\n",
      "epoch 4 batch 1000 loss 0.0005703003406524658\n",
      "epoch 5 batch 0 loss 0.0005427975654602051\n",
      "epoch 5 batch 500 loss 0.0008148493766784668\n",
      "epoch 5 batch 1000 loss 0.0007011407613754273\n",
      "epoch 6 batch 0 loss 0.0005782051682472229\n",
      "epoch 6 batch 500 loss 0.0007100459933280944\n",
      "epoch 6 batch 1000 loss 0.000583530068397522\n",
      "epoch 7 batch 0 loss 0.0004989306926727295\n",
      "epoch 7 batch 500 loss 0.0007375928163528443\n",
      "epoch 7 batch 1000 loss 0.0005223219990730286\n",
      "epoch 8 batch 0 loss 0.0003766137361526489\n",
      "epoch 8 batch 500 loss 0.0006645953059196472\n",
      "epoch 8 batch 1000 loss 0.0005626054406166076\n",
      "epoch 9 batch 0 loss 0.0004442984163761139\n",
      "epoch 9 batch 500 loss 0.0005366193056106567\n",
      "epoch 9 batch 1000 loss 0.0004564070403575897\n",
      "epoch 10 batch 0 loss 0.0005210212469100952\n",
      "epoch 10 batch 500 loss 0.00038879582285881043\n",
      "epoch 10 batch 1000 loss 0.0005827893018722534\n",
      "epoch 11 batch 0 loss 0.0004788142740726471\n",
      "epoch 11 batch 500 loss 0.000565498173236847\n",
      "epoch 11 batch 1000 loss 0.000542009711265564\n",
      "epoch 12 batch 0 loss 0.0005185520052909851\n",
      "epoch 12 batch 500 loss 0.0005146616101264954\n",
      "epoch 12 batch 1000 loss 0.0005456383228302002\n",
      "epoch 13 batch 0 loss 0.0004853916764259338\n",
      "epoch 13 batch 500 loss 0.0006278860569000244\n",
      "epoch 13 batch 1000 loss 0.0004758903086185455\n",
      "epoch 14 batch 0 loss 0.00040071424841880797\n",
      "epoch 14 batch 500 loss 0.0004697200059890747\n",
      "epoch 14 batch 1000 loss 0.0005012016892433167\n",
      "epoch 15 batch 0 loss 0.0004003239572048187\n",
      "epoch 15 batch 500 loss 0.0004394243657588959\n",
      "epoch 15 batch 1000 loss 0.00042753639817237854\n",
      "epoch 16 batch 0 loss 0.0005992160439491272\n",
      "epoch 16 batch 500 loss 0.0004999871551990509\n",
      "epoch 16 batch 1000 loss 0.00047112229466438293\n",
      "epoch 17 batch 0 loss 0.0002555628418922424\n",
      "epoch 17 batch 500 loss 0.0003033924400806427\n",
      "epoch 17 batch 1000 loss 0.0005567006468772889\n",
      "epoch 18 batch 0 loss 0.00029042544960975646\n",
      "epoch 18 batch 500 loss 0.0005365117192268372\n",
      "epoch 18 batch 1000 loss 0.00047091969847679136\n",
      "epoch 19 batch 0 loss 0.0005543380379676819\n",
      "epoch 19 batch 500 loss 0.00043623432517051695\n",
      "epoch 19 batch 1000 loss 0.0003064300417900085\n",
      "epoch 20 batch 0 loss 0.0003768454194068909\n",
      "epoch 20 batch 500 loss 0.0004191211462020874\n",
      "epoch 20 batch 1000 loss 0.00021320576965808867\n",
      "epoch 21 batch 0 loss 0.0002466757297515869\n",
      "epoch 21 batch 500 loss 0.00035843929648399355\n",
      "epoch 21 batch 1000 loss 0.0003666325807571411\n",
      "epoch 22 batch 0 loss 0.0004461607933044434\n",
      "epoch 22 batch 500 loss 0.0003995181620121002\n",
      "epoch 22 batch 1000 loss 0.00034122255444526674\n",
      "epoch 23 batch 0 loss 0.0003916413187980652\n",
      "epoch 23 batch 500 loss 0.00046359270811080933\n",
      "epoch 23 batch 1000 loss 0.00034044113755226133\n",
      "epoch 24 batch 0 loss 0.00032050859928131105\n",
      "epoch 24 batch 500 loss 0.00034554213285446165\n",
      "epoch 24 batch 1000 loss 0.00042502444982528686\n",
      "epoch 25 batch 0 loss 0.0004019788205623627\n",
      "epoch 25 batch 500 loss 0.0003249240815639496\n",
      "epoch 25 batch 1000 loss 0.00035759022831916807\n",
      "epoch 26 batch 0 loss 0.00024491053819656374\n",
      "epoch 26 batch 500 loss 0.00023421238362789155\n",
      "epoch 26 batch 1000 loss 0.00024044553935527802\n",
      "epoch 27 batch 0 loss 0.0003445285558700561\n",
      "epoch 27 batch 500 loss 0.0004139375686645508\n",
      "epoch 27 batch 1000 loss 0.0003795577883720398\n",
      "epoch 28 batch 0 loss 0.00033447566628456115\n",
      "epoch 28 batch 500 loss 0.00037535205483436586\n",
      "epoch 28 batch 1000 loss 0.00024462437629699707\n",
      "epoch 29 batch 0 loss 0.0003151333630084991\n",
      "epoch 29 batch 500 loss 0.00021551035344600678\n",
      "epoch 29 batch 1000 loss 0.0003359263241291046\n",
      "epoch 30 batch 0 loss 0.0001967211216688156\n",
      "epoch 30 batch 500 loss 0.0002602787613868713\n",
      "epoch 30 batch 1000 loss 0.00022364047169685363\n",
      "epoch 31 batch 0 loss 0.00029554104804992674\n",
      "epoch 31 batch 500 loss 0.000230840802192688\n",
      "epoch 31 batch 1000 loss 0.00028572243452072146\n",
      "epoch 32 batch 0 loss 0.00020317348837852478\n",
      "epoch 32 batch 500 loss 0.000258050411939621\n",
      "epoch 32 batch 1000 loss 0.0001898658722639084\n",
      "epoch 33 batch 0 loss 0.0003079630136489868\n",
      "epoch 33 batch 500 loss 0.0001923065185546875\n",
      "epoch 33 batch 1000 loss 0.0001760105937719345\n",
      "epoch 34 batch 0 loss 0.00018573948740959167\n",
      "epoch 34 batch 500 loss 0.0002625783085823059\n",
      "epoch 34 batch 1000 loss 0.0003746315836906433\n",
      "epoch 35 batch 0 loss 0.0001901031732559204\n",
      "epoch 35 batch 500 loss 0.00020961877703666687\n",
      "epoch 35 batch 1000 loss 0.00025042504072189333\n",
      "epoch 36 batch 0 loss 0.0003191078007221222\n",
      "epoch 36 batch 500 loss 0.0001488487124443054\n",
      "epoch 36 batch 1000 loss 0.00021406656503677367\n",
      "epoch 37 batch 0 loss 0.00022083984315395355\n",
      "epoch 37 batch 500 loss 0.00014451763033866883\n",
      "epoch 37 batch 1000 loss 0.00020647498965263366\n",
      "epoch 38 batch 0 loss 0.00012046044319868088\n",
      "epoch 38 batch 500 loss 0.0002478402853012085\n",
      "epoch 38 batch 1000 loss 0.00012182459235191346\n",
      "epoch 39 batch 0 loss 0.00030051839351654053\n",
      "epoch 39 batch 500 loss 0.00016421195864677428\n",
      "epoch 39 batch 1000 loss 0.00022364853322505952\n",
      "epoch 40 batch 0 loss 0.00018942022323608398\n",
      "epoch 40 batch 500 loss 0.0003239984214305878\n",
      "epoch 40 batch 1000 loss 0.00027609476447105406\n",
      "epoch 41 batch 0 loss 0.00023547202348709107\n",
      "epoch 41 batch 500 loss 0.0002643277645111084\n",
      "epoch 41 batch 1000 loss 0.0002190277725458145\n",
      "epoch 42 batch 0 loss 0.00013612966239452361\n",
      "epoch 42 batch 500 loss 0.0001381434053182602\n",
      "epoch 42 batch 1000 loss 0.00031671315431594846\n",
      "epoch 43 batch 0 loss 0.00012913554906845092\n",
      "epoch 43 batch 500 loss 0.0001055077686905861\n",
      "epoch 43 batch 1000 loss 0.00014507527649402618\n",
      "epoch 44 batch 0 loss 0.00034507253766059875\n",
      "epoch 44 batch 500 loss 0.00031331348419189455\n",
      "epoch 44 batch 1000 loss 0.00011416465789079666\n",
      "epoch 45 batch 0 loss 6.99864774942398e-05\n",
      "epoch 45 batch 500 loss 0.00036952316761016844\n",
      "epoch 45 batch 1000 loss 0.00016514685750007628\n",
      "epoch 46 batch 0 loss 0.0003526577651500702\n",
      "epoch 46 batch 500 loss 0.00010743298381567001\n",
      "epoch 46 batch 1000 loss 0.00017787939310073852\n",
      "epoch 47 batch 0 loss 9.394852072000504e-05\n",
      "epoch 47 batch 500 loss 0.00028702369332313536\n",
      "epoch 47 batch 1000 loss 0.00011494632065296174\n",
      "epoch 48 batch 0 loss 6.65334239602089e-05\n",
      "epoch 48 batch 500 loss 0.00017555296421051025\n",
      "epoch 48 batch 1000 loss 0.00018764249980449677\n",
      "epoch 49 batch 0 loss 2.9952291399240492e-05\n",
      "epoch 49 batch 500 loss 7.403125613927842e-05\n",
      "epoch 49 batch 1000 loss 0.00017235833406448366\n",
      "epoch 50 batch 0 loss 8.153612911701202e-05\n",
      "epoch 50 batch 500 loss 0.00010420704632997513\n",
      "epoch 50 batch 1000 loss 7.05089196562767e-05\n",
      "epoch 51 batch 0 loss 0.00010321597009897232\n",
      "epoch 51 batch 500 loss 0.00010337577760219573\n",
      "epoch 51 batch 1000 loss 0.00019257277250289917\n",
      "epoch 52 batch 0 loss 3.7025008350610736e-05\n",
      "epoch 52 batch 500 loss 0.00013561680912971497\n",
      "epoch 52 batch 1000 loss 0.00021637022495269776\n",
      "epoch 53 batch 0 loss 9.881587326526642e-05\n",
      "epoch 53 batch 500 loss 5.0397515296936034e-05\n",
      "epoch 53 batch 1000 loss 0.00015519432723522188\n",
      "epoch 54 batch 0 loss 6.688201427459717e-05\n",
      "epoch 54 batch 500 loss 0.00015664313733577728\n",
      "epoch 54 batch 1000 loss 0.0001584288626909256\n",
      "epoch 55 batch 0 loss 0.00027646702527999876\n",
      "epoch 55 batch 500 loss 0.00011378685384988785\n",
      "epoch 55 batch 1000 loss 5.1374595612287524e-05\n",
      "epoch 56 batch 0 loss 0.00013194873929023743\n",
      "epoch 56 batch 500 loss 9.024789929389954e-05\n",
      "epoch 56 batch 1000 loss 0.00016062964498996736\n",
      "epoch 57 batch 0 loss 0.00015853303670883178\n",
      "epoch 57 batch 500 loss 0.00012860286235809326\n",
      "epoch 57 batch 1000 loss 0.00015302234888076784\n",
      "epoch 58 batch 0 loss 3.3725067973136905e-05\n",
      "epoch 58 batch 500 loss 6.971445679664611e-05\n",
      "epoch 58 batch 1000 loss 0.00022910694777965546\n",
      "epoch 59 batch 0 loss 4.6072933822870256e-05\n",
      "epoch 59 batch 500 loss 7.126087695360184e-05\n",
      "epoch 59 batch 1000 loss 0.00011207051575183869\n",
      "epoch 60 batch 0 loss 0.00017534078657627106\n",
      "epoch 60 batch 500 loss 0.00018138720095157624\n",
      "epoch 60 batch 1000 loss 0.0005172119140625\n",
      "epoch 61 batch 0 loss 0.00014512962102890015\n",
      "epoch 61 batch 500 loss 6.459160894155502e-05\n",
      "epoch 61 batch 1000 loss 0.00013913214206695557\n",
      "epoch 62 batch 0 loss 3.643306344747543e-05\n",
      "epoch 62 batch 500 loss 1.9951261579990388e-05\n",
      "epoch 62 batch 1000 loss 0.00020989301800727845\n",
      "epoch 63 batch 0 loss 0.00012121298909187317\n",
      "epoch 63 batch 500 loss 0.00016786305606365204\n",
      "epoch 63 batch 1000 loss 0.00022695447504520415\n",
      "epoch 64 batch 0 loss 7.88796916604042e-05\n",
      "epoch 64 batch 500 loss 0.00013499251008033752\n",
      "epoch 64 batch 1000 loss 0.00010391464829444885\n",
      "epoch 65 batch 0 loss 7.261864095926285e-05\n",
      "epoch 65 batch 500 loss 7.291364669799805e-05\n",
      "epoch 65 batch 1000 loss 0.00024189502000808715\n",
      "epoch 66 batch 0 loss 0.00015294161438941955\n",
      "epoch 66 batch 500 loss 0.0001028798446059227\n",
      "epoch 66 batch 1000 loss 0.00011894999444484711\n",
      "epoch 67 batch 0 loss 9.735938161611557e-05\n",
      "epoch 67 batch 500 loss 0.00013171905279159545\n",
      "epoch 67 batch 1000 loss 0.00016223987936973572\n",
      "epoch 68 batch 0 loss 9.976759552955627e-05\n",
      "epoch 68 batch 500 loss 5.487407371401787e-05\n",
      "epoch 68 batch 1000 loss 4.032475128769875e-05\n",
      "epoch 69 batch 0 loss 7.019267231225968e-05\n",
      "epoch 69 batch 500 loss 3.2067686319351194e-05\n",
      "epoch 69 batch 1000 loss 0.00017329104244709015\n",
      "epoch 70 batch 0 loss 4.967917501926422e-05\n",
      "epoch 70 batch 500 loss 0.00023750995099544524\n",
      "epoch 70 batch 1000 loss 0.00028525054454803467\n",
      "epoch 71 batch 0 loss 0.0001174568384885788\n",
      "epoch 71 batch 500 loss 8.295658230781556e-05\n",
      "epoch 71 batch 1000 loss 2.05868910998106e-05\n",
      "epoch 72 batch 0 loss 6.069127470254898e-05\n",
      "epoch 72 batch 500 loss 1.9202571362257003e-05\n",
      "epoch 72 batch 1000 loss 5.856975167989731e-05\n",
      "epoch 73 batch 0 loss 6.824424862861633e-05\n",
      "epoch 73 batch 500 loss 8.838832378387452e-05\n",
      "epoch 73 batch 1000 loss 2.8816426172852515e-05\n",
      "epoch 74 batch 0 loss 0.00010094540566205979\n",
      "epoch 74 batch 500 loss 0.00011339271813631058\n",
      "epoch 74 batch 1000 loss 4.7543946653604507e-05\n",
      "epoch 75 batch 0 loss 7.249550521373749e-05\n",
      "epoch 75 batch 500 loss 4.188087582588196e-05\n",
      "epoch 75 batch 1000 loss 5.616245046257973e-05\n",
      "epoch 76 batch 0 loss 2.043651044368744e-05\n",
      "epoch 76 batch 500 loss 7.438768446445466e-05\n",
      "epoch 76 batch 1000 loss 0.00012592560052871704\n",
      "epoch 77 batch 0 loss 3.721144050359726e-05\n",
      "epoch 77 batch 500 loss 1.725003868341446e-05\n",
      "epoch 77 batch 1000 loss 0.0001016056090593338\n",
      "epoch 78 batch 0 loss 2.1402981132268907e-05\n",
      "epoch 78 batch 500 loss 7.667021453380585e-05\n",
      "epoch 78 batch 1000 loss 9.850815683603286e-05\n",
      "epoch 79 batch 0 loss 5.51980659365654e-05\n",
      "epoch 79 batch 500 loss 0.00013815565407276152\n",
      "epoch 79 batch 1000 loss 0.00021486370265483856\n",
      "epoch 80 batch 0 loss 5.306750908493995e-05\n",
      "epoch 80 batch 500 loss 0.0001078428104519844\n",
      "epoch 80 batch 1000 loss 0.0001482120007276535\n",
      "epoch 81 batch 0 loss 0.00011411270499229431\n",
      "epoch 81 batch 500 loss 5.943076312541962e-05\n",
      "epoch 81 batch 1000 loss 5.028774216771126e-05\n",
      "epoch 82 batch 0 loss 4.5650962740182875e-05\n",
      "epoch 82 batch 500 loss 4.515029489994049e-05\n",
      "epoch 82 batch 1000 loss 8.556102216243744e-05\n",
      "epoch 83 batch 0 loss 0.0001222199574112892\n",
      "epoch 83 batch 500 loss 5.4877705872058866e-05\n",
      "epoch 83 batch 1000 loss 9.951348602771759e-05\n",
      "epoch 84 batch 0 loss 9.518346935510635e-05\n",
      "epoch 84 batch 500 loss 9.208405762910843e-05\n",
      "epoch 84 batch 1000 loss 8.733735233545303e-05\n",
      "epoch 85 batch 0 loss 4.488292336463928e-05\n",
      "epoch 85 batch 500 loss 2.9491221532225608e-05\n",
      "epoch 85 batch 1000 loss 8.878713846206666e-05\n",
      "epoch 86 batch 0 loss 5.171491950750351e-05\n",
      "epoch 86 batch 500 loss 8.524626493453979e-06\n",
      "epoch 86 batch 1000 loss 9.72174033522606e-05\n",
      "epoch 87 batch 0 loss 3.450924158096314e-05\n",
      "epoch 87 batch 500 loss 5.87976211681962e-06\n",
      "epoch 87 batch 1000 loss 3.649570420384407e-05\n",
      "epoch 88 batch 0 loss 4.2844109237194064e-05\n",
      "epoch 88 batch 500 loss 8.005642145872116e-05\n",
      "epoch 88 batch 1000 loss 6.120091676712036e-05\n",
      "epoch 89 batch 0 loss 0.00014036481082439423\n",
      "epoch 89 batch 500 loss 8.614619076251983e-05\n",
      "epoch 89 batch 1000 loss 1.2520984746515751e-05\n",
      "epoch 90 batch 0 loss 4.460103064775467e-05\n",
      "epoch 90 batch 500 loss 0.00023352135717868804\n",
      "epoch 90 batch 1000 loss 5.1214549690485e-05\n",
      "epoch 91 batch 0 loss 0.00017971199750900269\n",
      "epoch 91 batch 500 loss 1.3806537725031375e-05\n",
      "epoch 91 batch 1000 loss 7.12282657623291e-05\n",
      "epoch 92 batch 0 loss 1.763487607240677e-05\n",
      "epoch 92 batch 500 loss 0.00016219684481620788\n",
      "epoch 92 batch 1000 loss 6.914345920085907e-05\n",
      "epoch 93 batch 0 loss 5.6787975132465366e-05\n",
      "epoch 93 batch 500 loss 0.00018731218576431276\n",
      "epoch 93 batch 1000 loss 0.00021161702275276185\n",
      "epoch 94 batch 0 loss 1.6946826130151748e-05\n",
      "epoch 94 batch 500 loss 1.482333242893219e-05\n",
      "epoch 94 batch 1000 loss 0.00010020584613084793\n",
      "epoch 95 batch 0 loss 2.9553152620792387e-05\n",
      "epoch 95 batch 500 loss 8.335778862237931e-05\n",
      "epoch 95 batch 1000 loss 6.321198772639036e-06\n",
      "epoch 96 batch 0 loss 3.1156755983829497e-05\n",
      "epoch 96 batch 500 loss 7.777422666549683e-05\n",
      "epoch 96 batch 1000 loss 2.4199331179261207e-05\n",
      "epoch 97 batch 0 loss 8.586383610963822e-05\n",
      "epoch 97 batch 500 loss 4.2692113667726514e-05\n",
      "epoch 97 batch 1000 loss 5.385785549879074e-05\n",
      "epoch 98 batch 0 loss 8.51123183965683e-05\n",
      "epoch 98 batch 500 loss 0.00014055949449539185\n",
      "epoch 98 batch 1000 loss 0.0001997263729572296\n",
      "epoch 99 batch 0 loss 8.796193636953831e-06\n",
      "epoch 99 batch 500 loss 1.2655710801482201e-05\n",
      "epoch 99 batch 1000 loss 0.00012085132300853729\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        #获取输入\n",
    "        sample_images, sample_labels = batch\n",
    "\n",
    "        # 参数梯度归零\n",
    "        # 默认情况下，pytorch在反向传递中会累积梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        predicted_labels = net(sample_images)\n",
    "        loss = criterion(predicted_labels, sample_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # 每五百个小批量打印一次\n",
    "        if batch_index % 500 == 0:\n",
    "            print(f\"epoch {epoch} batch {batch_index} loss {running_loss / 2000}\")\n",
    "        running_loss = 0\n",
    "\n",
    "    loss = criterion(predicted_labels, sample_labels)\n",
    "    train_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0399e2-fdff-4c9d-bc52-3e673f7323d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set linked successfully\n"
     ]
    }
   ],
   "source": [
    "# 创建测试集图像目录\n",
    "os.makedirs(TEST_IMAGES_REORGANIZED_PATH, exist_ok=True)\n",
    "\n",
    "# 检查是否已经存在链接\n",
    "if os.path.islink(TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH):\n",
    "    print(\"Test set has been already linked\")\n",
    "else:\n",
    "    # 创建符号链接\n",
    "    os.system(f\"mklink /D {TEST_IMAGES_REORGANIZED_PLACEHOLDER_LABEL_PATH} {TEST_FULL_IMAGES_PATH}\")\n",
    "    print(\"Test set linked successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "123451df-b0ae-4a45-bf25-15c34d8dda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = ImageFolder(TEST_IMAGES_REORGANIZED_PATH, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9895e5c4-66d7-4f9b-8c41-ca662dc92e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_images, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "preds = []\n",
    "for X, _ in test_loader:\n",
    "    y_hat = net(X)\n",
    "    preds.extend(y_hat.argmax(dim=1))\n",
    "# 从测试集图像路径中提取图像的 id（去掉路径前缀和文件扩展名）\n",
    "# 从测试集图像路径中提取图像的 id（去掉路径前缀和文件扩展名）\n",
    "ids = [os.path.splitext(os.path.basename(path))[0] for path, _ in test_loader.dataset.imgs]\n",
    "\n",
    "# 创建一个DataFrame，其中包含图像的id和对应的预测标签\n",
    "df = pd.DataFrame({'id': ids, 'label': map(lambda i: train_images.classes[i], preds)})\n",
    "\n",
    "# 将DataFrame保存到CSV文件中\n",
    "df.to_csv('./imageclassification/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a579ec-4ce4-4f5b-9dd9-6f270c109290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions: 5797\n",
      "0.5797\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取正确标签的CSV文件，假设文件名为 'true_labels.csv'\n",
    "true_labels = pd.read_csv('./imageclassification/temp/testLables.csv', index_col='id')\n",
    "\n",
    "# 读取预测标签的CSV文件，假设文件名为 'predicted_labels.csv'\n",
    "predicted_labels = pd.read_csv('./imageclassification/working/submission.csv', index_col='id')\n",
    "\n",
    "# 将两个DataFrame按照id进行合并\n",
    "merged_data = pd.merge(true_labels, predicted_labels, left_index=True, right_index=True, suffixes=('_true', '_predicted'))\n",
    "\n",
    "# 统计正确的数量\n",
    "correct_count = (merged_data['label_true'] == merged_data['label_predicted']).sum()\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Number of correct predictions: {correct_count}\")\n",
    "accury = correct_count/10000\n",
    "print(accury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beff1f9-1783-49d2-999c-633820dbc58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
